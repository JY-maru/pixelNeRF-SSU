# Pixel-NeRF: Multi-View Stereo Enhanced (in Colab)

ë³¸ í”„ë¡œì íŠ¸ëŠ” **Pixel-NeRF** (Yu et al., 2021)ì˜ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, **Multi-View Stereo (MVS)** ê°œë…(Variance ê¸°ë°˜ ì •í•©ì„± íŒë‹¨)ê³¼ **FPN(Feature Pyramid Network)** ì„ ë„ì…í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•œ êµ¬í˜„ì²´ì…ë‹ˆë‹¤.

Colab í™˜ê²½ì—ì„œë„ **ì•½ 30ì‹œê°„** ì˜ í•™ìŠµë§Œìœ¼ë¡œ ShapeNet ì°¨ëŸ‰ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì¤€ìˆ˜í•œ 3D í˜•ìƒì„ ë³µì›í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

<br>

## ğŸ¥ Demo Results
/rendering_demo.gif

<br>

---

## âš¡ Context & Optimization Strategy

í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” GPU í™˜ê²½ì— ì†ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” Colab í™˜ê²½ ë‚´ì—ì„œ pixel-NeRFë¥¼ í™œìš©í•˜ê³ , ê·¸ì— ë”°ë¥¸ ìµœìƒì˜ ê¸°í•˜í•™ì  í’ˆì§ˆì„ ì–»ëŠ” ê²ƒì…ë‹ˆë‹¤. ì œí•œëœ GPU ì‚¬ìš©ëŸ‰ì„ ê³ ë ¤í•˜ì—¬ ê¸°ì¡´ì˜ Few-shot(1~2ë·°) í•™ìŠµ ë°©ì‹ ëŒ€ì‹ , **ë©€í‹° ë·°(6-views)** ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì‹œê°„ì„ ì¤„ì´ê³  ë¹ ë¥´ê²Œ í•™ìŠµë  ìˆ˜ ìˆê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤. 

| êµ¬ë¶„ | Original Pixel-NeRF | **Ours (Colab Optimized)** |
| :--- | :--- | :--- |
| **Environment** | Heavy Workstation | **Google Colab (Ready-to-Run)** |
| **Input Views** | 1 ~ 2 Views (Sparse) | **6 Views (Geometric Constraints)** |
| **Training Time** | 6 Days+ (V100) | **30 Hours (A100)** |
| **Steps** | 400k+ Steps | **100k Steps (Early Convergence)** |
| **Dataset** | ShapeNet (Cars) | ShapeNet (Cars) |

<br>

---

## ğŸš€ Getting Started (Colab Friendly)

ì´ ì½”ë“œëŠ” **Google Colab** í™˜ê²½ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë³„ë„ì˜ ë³µì¡í•œ í™˜ê²½ ì„¤ì • ì—†ì´ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### 1. Environment Setup
Colab ë…¸íŠ¸ë¶ì—ì„œ ë³„ë„ì˜ ê°€ìƒí™˜ê²½ ì„¤ì • ì—†ì´, í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì„¤ì¹˜í•˜ë©´ ì¦‰ì‹œ ì‘ë™í•©ë‹ˆë‹¤.
```bash
# Colab ì…€ì—ì„œ ì‹¤í–‰
!pip install imageio tqdm matplotlib configargparse

```

### 2. Data Loading (One-Line Command)

ë³µì¡í•œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ê³¼ì • ì—†ì´, ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ í•™ìŠµì— í•„ìš”í•œ ShapeNet ë°ì´í„°ë¥¼ ì¦‰ì‹œ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# Colab ì…€ì—ì„œ ì‹¤í–‰
!bash fetch2local.sh -from nerf-data-ssu/shapeNetV2_cars

```

* *ë°ì´í„°ëŠ” ìë™ìœ¼ë¡œ í˜„ì¬ í™˜ê²½ì— ë§ê²Œ êµ¬ì„±ë©ë‹ˆë‹¤.*

### 3. Training

```bash
# ê¸°ë³¸ ì„¤ì •(6 views, 100k steps)ìœ¼ë¡œ í•™ìŠµ ì‹œì‘
python train.py --config config/default_config.yaml

```

* *Tip: ìµœì´ˆ ì‹¤í–‰ ì‹œ ê¸°í•˜í•™ì  í•„í„°ë§ì„ ìœ„í•œ ìºì‹œ(`.pt`) ìƒì„±ìœ¼ë¡œ ì¸í•´ ì‹œì‘ì— ì•½ 5~10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*

### 4. Inference (Video Generation)

```bash
python inference.py --input_folder ./data/cars_test/object_id \
                    --checkpoint checkpoints/best_model.pth \
                    --mode video \
                    --num_frames 90

```

---

## ğŸ—ï¸ Technical Enhancements: How it works?

ë‹¨ìˆœíˆ ë·° ê°œìˆ˜ë§Œ ëŠ˜ë¦° ê²ƒì´ ì•„ë‹ˆë¼, ëŠ˜ì–´ë‚œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ **Stereo Matching** ì— ì í•©í•œ êµ¬ì¡°ë¡œ ê³ ë„í™”í–ˆìŠµë‹ˆë‹¤.

### 1. Multi-Scale Feature Extraction (FPN)

* **ê¸°ì¡´:** ResNetì˜ ë‹¨ì¼ ë ˆì´ì–´ íŠ¹ì§•ë§µë§Œ ì‚¬ìš© (ì •ë³´ ì†ì‹¤ ë°œìƒ).
* **ê°œì„ :** **FPN (Feature Pyramid Network)** ì„ ê²°í•©í•˜ì—¬, **4ê°€ì§€ í•´ìƒë„( ~ )ì˜ íŠ¹ì§•ë§µ** ê³¼ **ì›ë³¸ RGB** ë¥¼ ëª¨ë‘ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ NeRF í—¤ë“œì— ì „ë‹¬í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë””í…Œì¼ê³¼ ì „ì²´ í˜•ìƒì„ ë™ì‹œì— í•™ìŠµí•©ë‹ˆë‹¤.

### 2. Early Fusion with Variance Injection

* **ê¸°ì¡´:** ì—¬ëŸ¬ ë·°ì˜ íŠ¹ì§•ì„ ë‹¨ìˆœíˆ í‰ê· (Average)ë‚´ì–´ MLPì— ì „ë‹¬. ë·° ê°„ì˜ ì°¨ì´(ë¶ˆì¼ì¹˜) ì •ë³´ê°€ ì‚¬ë¼ì§.
* **ê°œì„ :** MVS(Multi-View Stereo)ì˜ í•µì‹¬ì¸ **ë¶„ì‚°(Variance)**ì„ í•¨ê»˜ ê³„ì‚°í•˜ì—¬ MLP ì…ë ¥ë‹¨ì— ì£¼ì…(**Early Fusion**)í–ˆìŠµë‹ˆë‹¤.
* **Varianceì˜ ì—­í• :** "ì´ ì§€ì ì—ì„œ 6ê°œì˜ ì¹´ë©”ë¼ê°€ ê°™ì€ ìƒ‰ìƒì„ ë³´ê³  ìˆëŠ”ê°€?"ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤. ë¶„ì‚°ì´ ë‚®ë‹¤ë©´ ë¬¼ì²´ í‘œë©´ì¼ í™•ë¥ ì´ ë†’ë‹¤ëŠ” ê°•ë ¥í•œ ì‹ í˜¸(Stereo Cue)ê°€ ë©ë‹ˆë‹¤.



### 3. Smart Data Filtering

* **Geometric Pruning:** í•™ìŠµì— ë°©í•´ê°€ ë˜ëŠ” 'ë°”ë‹¥(Floor)' ë·°ë‚˜ 'ì •ìˆ˜ë¦¬(Top-down)' ë·°ë¥¼ ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ê¸°ë°˜ìœ¼ë¡œ ìˆ˜í•™ì ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì‚¬ì „ì— ì œê±°í–ˆìŠµë‹ˆë‹¤.

---

## Acknowledgement

This project builds upon [Pixel-NeRF](https://github.com/sxyu/pixel-nerf). We optimized it for constrained environments by introducing **FPN encoders**, **Variance-based feature aggregation**, and **Geometric data pruning**.


---
